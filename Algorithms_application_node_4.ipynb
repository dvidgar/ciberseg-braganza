{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c4b1cfd",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6c6197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib.pyplot import axes, title\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn import metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281f9646",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5562f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set for the fourth IoT node\n",
    "benign_4 = pd.read_csv(\"C:/Users/gustavo/Documents/Jupyter_notebook/archive/4.benign.csv\")\n",
    "#g_scan_4 = pd.read_csv(\"C:/Users/gustavo/Documents/Jupyter_notebook/archive/4.gafgyt.scan.csv\")\n",
    "#g_junk_4 = pd.read_csv(\"C:/Users/gustavo/Documents/Jupyter_notebook/archive/4.gafgyt.junk.csv\")\n",
    "#g_udp_4 = pd.read_csv(\"C:/Users/gustavo/Documents/Jupyter_notebook/archive/4.gafgyt.udp.csv\")\n",
    "#g_tcp_4 = pd.read_csv(\"C:/Users/gustavo/Documents/Jupyter_notebook/archive/4.gafgyt.tcp.csv\")\n",
    "g_combo_4 = pd.read_csv(\"C:/Users/gustavo/Documents/Jupyter_notebook/archive/4.gafgyt.combo.csv\")\n",
    "#m_scan_4 = pd.read_csv(\"C:/Users/gustavo/Documents/Jupyter_notebook/archive/4.mirai.scan.csv\")\n",
    "#m_ack_4 = pd.read_csv(\"C:/Users/gustavo/Documents/Jupyter_notebook/archive/4.mirai.ack.csv\")\n",
    "#m_syn_4 = pd.read_csv(\"C:/Users/gustavo/Documents/Jupyter_notebook/archive/4.mirai.syn.csv\")\n",
    "#m_udp_4 = pd.read_csv(\"C:/Users/gustavo/Documents/Jupyter_notebook/archive/4.mirai.udp.csv\")\n",
    "#m_p_udp_4 = pd.read_csv(\"C:/Users/gustavo/Documents/Jupyter_notebook/archive/4.mirai.udpplain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e6a7fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape==> Benign shape:  (175240, 115) // Bashlite combo:  (58152, 115)\n"
     ]
    }
   ],
   "source": [
    "print\n",
    "print('Shape==>', 'Benign shape: ', benign_4.shape, '//','Bashlite combo: ', g_combo_4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7232bce",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f27f099",
   "metadata": {},
   "source": [
    "-- The following describes each of the features headers:\n",
    "\n",
    "* Stream aggregation:\n",
    "H: Stats summarizing the recent traffic from this packet's host (IP)\n",
    "HH: Stats summarizing the recent traffic going from this packet's host (IP) to the packet's destination host.\n",
    "HpHp: Stats summarizing the recent traffic going from this packet's host+port (IP) to the packet's destination host+port. Example 192.168.4.2:1242 -> 192.168.4.12:80\n",
    "HH_jit: Stats summarizing the jitter of the traffic going from this packet's host (IP) to the packet's destination host.\n",
    "\n",
    "* Time-frame (The decay factor Lambda used in the damped window):\n",
    "How much recent history of the stream is capture in these statistics\n",
    "L5, L3, L1, ...\n",
    "\n",
    "* The statistics extracted from the packet stream:\n",
    "weight: The weight of the stream (can be viewed as the number of items observed in recent history)\n",
    "mean: ...\n",
    "std: ...\n",
    "radius: The root squared sum of the two streams' variances\n",
    "magnitude: The root squared sum of the two streams' means\n",
    "cov: an approximated covariance between two streams\n",
    "pcc: an approximated covariance between two streams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d39dcf",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90c87e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "benign=benign_4.sample(frac=0.25,replace=False)\n",
    "g_combo=g_combo_4.sample(frac=0.25,replace=False)\n",
    "#g_junk=g_junk_4.sample(frac=0.5,replace=False)\n",
    "#g_scan=g_scan_4.sample(frac=0.5,replace=False)\n",
    "#g_tcp=g_tcp_4.sample(frac=0.15,replace=False)\n",
    "#g_udp=g_udp_4.sample(frac=0.15,replace=False)\n",
    "#m_ack=m_ack_4.sample(frac=0.25,replace=False)\n",
    "#m_scan=m_scan_4.sample(frac=0.15,replace=False)\n",
    "#m_syn=m_syn_4.sample(frac=0.25,replace=False)\n",
    "#m_udp=m_udp_4.sample(frac=0.1,replace=False)\n",
    "#m_p_udp=m_p_udp_4.sample(frac=0.27,replace=False)\n",
    "\n",
    "\n",
    "benign['type']='benign'\n",
    "g_combo['type']='gafgyt_combo'\n",
    "#g_junk['type']='gafgyt_junk'\n",
    "#g_scan['type']='gafgyt_scan'\n",
    "#g_tcp['type']='gafgyt_tcp'\n",
    "#g_udp['type']='gafgyt_udp'\n",
    "#m_udp['type']='mirai_udp'\n",
    "#m_ack['type']='mirai_ack'\n",
    "#m_scan['type']='mirai_scan'\n",
    "#m_syn['type']='mirai_syn'\n",
    "#m_p_udp['type']='mirai_udpplain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ddc2f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=pd.concat([benign,m_udp,g_combo,g_junk,g_scan,g_tcp,g_udp,m_ack,m_scan,m_syn,m_p_udp],\n",
    "#               axis=0, sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deb1a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([benign,g_combo],\n",
    "               axis=0, sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ed89e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "benign          43810\n",
       "gafgyt_combo    14538\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many instances of each class\n",
    "data.groupby('type')['type'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a3127b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58348, 116)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c3b26f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L5_mean</th>\n",
       "      <th>MI_dir_L5_variance</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L3_mean</th>\n",
       "      <th>MI_dir_L3_variance</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L1_mean</th>\n",
       "      <th>MI_dir_L1_variance</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HpHp_L0.1_covariance</th>\n",
       "      <th>HpHp_L0.1_pcc</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "      <th>HpHp_L0.01_mean</th>\n",
       "      <th>HpHp_L0.01_std</th>\n",
       "      <th>HpHp_L0.01_magnitude</th>\n",
       "      <th>HpHp_L0.01_radius</th>\n",
       "      <th>HpHp_L0.01_covariance</th>\n",
       "      <th>HpHp_L0.01_pcc</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30069</th>\n",
       "      <td>1.003906</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>9.950000e-07</td>\n",
       "      <td>1.035997</td>\n",
       "      <td>65.999831</td>\n",
       "      <td>1.015688e-03</td>\n",
       "      <td>1.429683</td>\n",
       "      <td>65.885333</td>\n",
       "      <td>1.662340</td>\n",
       "      <td>10.452283</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.300000e-10</td>\n",
       "      <td>-1.050000e-06</td>\n",
       "      <td>18.488216</td>\n",
       "      <td>66.057505</td>\n",
       "      <td>0.828709</td>\n",
       "      <td>116.262918</td>\n",
       "      <td>217.397737</td>\n",
       "      <td>-0.245503</td>\n",
       "      <td>-0.020092</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3563</th>\n",
       "      <td>1.004649</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.040758</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>2.970000e-07</td>\n",
       "      <td>1.449353</td>\n",
       "      <td>66.025318</td>\n",
       "      <td>1.544761</td>\n",
       "      <td>9.867561</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.938604e+00</td>\n",
       "      <td>-1.563288e-01</td>\n",
       "      <td>18.294705</td>\n",
       "      <td>70.153435</td>\n",
       "      <td>6.971186</td>\n",
       "      <td>99.914476</td>\n",
       "      <td>73.747515</td>\n",
       "      <td>-1.438903</td>\n",
       "      <td>-0.027714</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9406</th>\n",
       "      <td>1.002598</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>2.000000e-06</td>\n",
       "      <td>1.028190</td>\n",
       "      <td>66.000151</td>\n",
       "      <td>1.358499e-02</td>\n",
       "      <td>1.422278</td>\n",
       "      <td>66.758823</td>\n",
       "      <td>67.718295</td>\n",
       "      <td>9.838075</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.850000e-12</td>\n",
       "      <td>-7.200000e-08</td>\n",
       "      <td>19.149283</td>\n",
       "      <td>66.079987</td>\n",
       "      <td>0.976445</td>\n",
       "      <td>115.448327</td>\n",
       "      <td>238.893604</td>\n",
       "      <td>-0.361232</td>\n",
       "      <td>-0.023935</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46005</th>\n",
       "      <td>173.158759</td>\n",
       "      <td>74.008213</td>\n",
       "      <td>1.970465e-01</td>\n",
       "      <td>278.762557</td>\n",
       "      <td>74.017608</td>\n",
       "      <td>4.222831e-01</td>\n",
       "      <td>806.631568</td>\n",
       "      <td>74.033050</td>\n",
       "      <td>0.796567</td>\n",
       "      <td>7330.415908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.677611</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.268043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>gafgyt_combo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36074</th>\n",
       "      <td>1.033480</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.130304</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>2.270000e-11</td>\n",
       "      <td>1.540639</td>\n",
       "      <td>66.000474</td>\n",
       "      <td>0.007630</td>\n",
       "      <td>8.924058</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.680000e-11</td>\n",
       "      <td>-9.940000e-07</td>\n",
       "      <td>19.118733</td>\n",
       "      <td>66.034240</td>\n",
       "      <td>0.640086</td>\n",
       "      <td>115.691611</td>\n",
       "      <td>232.107760</td>\n",
       "      <td>-0.246350</td>\n",
       "      <td>-0.025262</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  MI_dir_L3_weight  \\\n",
       "30069          1.003906       66.000000        9.950000e-07          1.035997   \n",
       "3563           1.004649       66.000000        0.000000e+00          1.040758   \n",
       "9406           1.002598       66.000000        2.000000e-06          1.028190   \n",
       "46005        173.158759       74.008213        1.970465e-01        278.762557   \n",
       "36074          1.033480       66.000000        0.000000e+00          1.130304   \n",
       "\n",
       "       MI_dir_L3_mean  MI_dir_L3_variance  MI_dir_L1_weight  MI_dir_L1_mean  \\\n",
       "30069       65.999831        1.015688e-03          1.429683       65.885333   \n",
       "3563        66.000000        2.970000e-07          1.449353       66.025318   \n",
       "9406        66.000151        1.358499e-02          1.422278       66.758823   \n",
       "46005       74.017608        4.222831e-01        806.631568       74.033050   \n",
       "36074       66.000000        2.270000e-11          1.540639       66.000474   \n",
       "\n",
       "       MI_dir_L1_variance  MI_dir_L0.1_weight  ...  HpHp_L0.1_covariance  \\\n",
       "30069            1.662340           10.452283  ...         -4.300000e-10   \n",
       "3563             1.544761            9.867561  ...         -7.938604e+00   \n",
       "9406            67.718295            9.838075  ...         -1.850000e-12   \n",
       "46005            0.796567         7330.415908  ...          0.000000e+00   \n",
       "36074            0.007630            8.924058  ...         -5.680000e-11   \n",
       "\n",
       "       HpHp_L0.1_pcc  HpHp_L0.01_weight  HpHp_L0.01_mean  HpHp_L0.01_std  \\\n",
       "30069  -1.050000e-06          18.488216        66.057505        0.828709   \n",
       "3563   -1.563288e-01          18.294705        70.153435        6.971186   \n",
       "9406   -7.200000e-08          19.149283        66.079987        0.976445   \n",
       "46005   0.000000e+00           1.677611        74.000000        0.000000   \n",
       "36074  -9.940000e-07          19.118733        66.034240        0.640086   \n",
       "\n",
       "       HpHp_L0.01_magnitude  HpHp_L0.01_radius  HpHp_L0.01_covariance  \\\n",
       "30069            116.262918         217.397737              -0.245503   \n",
       "3563              99.914476          73.747515              -1.438903   \n",
       "9406             115.448327         238.893604              -0.361232   \n",
       "46005             95.268043           0.000000               0.000000   \n",
       "36074            115.691611         232.107760              -0.246350   \n",
       "\n",
       "       HpHp_L0.01_pcc          type  \n",
       "30069       -0.020092        benign  \n",
       "3563        -0.027714        benign  \n",
       "9406        -0.023935        benign  \n",
       "46005        0.000000  gafgyt_combo  \n",
       "36074       -0.025262        benign  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffle rows of dataframe \n",
    "sampler=np.random.permutation(len(data))\n",
    "data=data.take(sampler)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7cc5bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_benign</th>\n",
       "      <th>type_gafgyt_combo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30069</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3563</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9406</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46005</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36074</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type_benign  type_gafgyt_combo\n",
       "30069            1                  0\n",
       "3563             1                  0\n",
       "9406             1                  0\n",
       "46005            0                  1\n",
       "36074            1                  0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dummy encode labels, store separately\n",
    "labels_full=pd.get_dummies(data['type'], prefix='type')\n",
    "labels_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79a49a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L5_mean</th>\n",
       "      <th>MI_dir_L5_variance</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L3_mean</th>\n",
       "      <th>MI_dir_L3_variance</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L1_mean</th>\n",
       "      <th>MI_dir_L1_variance</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HpHp_L0.1_radius</th>\n",
       "      <th>HpHp_L0.1_covariance</th>\n",
       "      <th>HpHp_L0.1_pcc</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "      <th>HpHp_L0.01_mean</th>\n",
       "      <th>HpHp_L0.01_std</th>\n",
       "      <th>HpHp_L0.01_magnitude</th>\n",
       "      <th>HpHp_L0.01_radius</th>\n",
       "      <th>HpHp_L0.01_covariance</th>\n",
       "      <th>HpHp_L0.01_pcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30069</th>\n",
       "      <td>1.003906</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>9.950000e-07</td>\n",
       "      <td>1.035997</td>\n",
       "      <td>65.999831</td>\n",
       "      <td>1.015688e-03</td>\n",
       "      <td>1.429683</td>\n",
       "      <td>65.885333</td>\n",
       "      <td>1.662340</td>\n",
       "      <td>10.452283</td>\n",
       "      <td>...</td>\n",
       "      <td>8.124168e+01</td>\n",
       "      <td>-4.300000e-10</td>\n",
       "      <td>-1.050000e-06</td>\n",
       "      <td>18.488216</td>\n",
       "      <td>66.057505</td>\n",
       "      <td>0.828709</td>\n",
       "      <td>116.262918</td>\n",
       "      <td>217.397737</td>\n",
       "      <td>-0.245503</td>\n",
       "      <td>-0.020092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3563</th>\n",
       "      <td>1.004649</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.040758</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>2.970000e-07</td>\n",
       "      <td>1.449353</td>\n",
       "      <td>66.025318</td>\n",
       "      <td>1.544761</td>\n",
       "      <td>9.867561</td>\n",
       "      <td>...</td>\n",
       "      <td>7.355762e+01</td>\n",
       "      <td>-7.938604e+00</td>\n",
       "      <td>-1.563288e-01</td>\n",
       "      <td>18.294705</td>\n",
       "      <td>70.153435</td>\n",
       "      <td>6.971186</td>\n",
       "      <td>99.914476</td>\n",
       "      <td>73.747515</td>\n",
       "      <td>-1.438903</td>\n",
       "      <td>-0.027714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9406</th>\n",
       "      <td>1.002598</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>2.000000e-06</td>\n",
       "      <td>1.028190</td>\n",
       "      <td>66.000151</td>\n",
       "      <td>1.358499e-02</td>\n",
       "      <td>1.422278</td>\n",
       "      <td>66.758823</td>\n",
       "      <td>67.718295</td>\n",
       "      <td>9.838075</td>\n",
       "      <td>...</td>\n",
       "      <td>1.447934e+02</td>\n",
       "      <td>-1.850000e-12</td>\n",
       "      <td>-7.200000e-08</td>\n",
       "      <td>19.149283</td>\n",
       "      <td>66.079987</td>\n",
       "      <td>0.976445</td>\n",
       "      <td>115.448327</td>\n",
       "      <td>238.893604</td>\n",
       "      <td>-0.361232</td>\n",
       "      <td>-0.023935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46005</th>\n",
       "      <td>173.158759</td>\n",
       "      <td>74.008213</td>\n",
       "      <td>1.970465e-01</td>\n",
       "      <td>278.762557</td>\n",
       "      <td>74.017608</td>\n",
       "      <td>4.222831e-01</td>\n",
       "      <td>806.631568</td>\n",
       "      <td>74.033050</td>\n",
       "      <td>0.796567</td>\n",
       "      <td>7330.415908</td>\n",
       "      <td>...</td>\n",
       "      <td>9.094947e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.677611</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.268043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36074</th>\n",
       "      <td>1.033480</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.130304</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>2.270000e-11</td>\n",
       "      <td>1.540639</td>\n",
       "      <td>66.000474</td>\n",
       "      <td>0.007630</td>\n",
       "      <td>8.924058</td>\n",
       "      <td>...</td>\n",
       "      <td>2.241835e+02</td>\n",
       "      <td>-5.680000e-11</td>\n",
       "      <td>-9.940000e-07</td>\n",
       "      <td>19.118733</td>\n",
       "      <td>66.034240</td>\n",
       "      <td>0.640086</td>\n",
       "      <td>115.691611</td>\n",
       "      <td>232.107760</td>\n",
       "      <td>-0.246350</td>\n",
       "      <td>-0.025262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  MI_dir_L3_weight  \\\n",
       "30069          1.003906       66.000000        9.950000e-07          1.035997   \n",
       "3563           1.004649       66.000000        0.000000e+00          1.040758   \n",
       "9406           1.002598       66.000000        2.000000e-06          1.028190   \n",
       "46005        173.158759       74.008213        1.970465e-01        278.762557   \n",
       "36074          1.033480       66.000000        0.000000e+00          1.130304   \n",
       "\n",
       "       MI_dir_L3_mean  MI_dir_L3_variance  MI_dir_L1_weight  MI_dir_L1_mean  \\\n",
       "30069       65.999831        1.015688e-03          1.429683       65.885333   \n",
       "3563        66.000000        2.970000e-07          1.449353       66.025318   \n",
       "9406        66.000151        1.358499e-02          1.422278       66.758823   \n",
       "46005       74.017608        4.222831e-01        806.631568       74.033050   \n",
       "36074       66.000000        2.270000e-11          1.540639       66.000474   \n",
       "\n",
       "       MI_dir_L1_variance  MI_dir_L0.1_weight  ...  HpHp_L0.1_radius  \\\n",
       "30069            1.662340           10.452283  ...      8.124168e+01   \n",
       "3563             1.544761            9.867561  ...      7.355762e+01   \n",
       "9406            67.718295            9.838075  ...      1.447934e+02   \n",
       "46005            0.796567         7330.415908  ...      9.094947e-13   \n",
       "36074            0.007630            8.924058  ...      2.241835e+02   \n",
       "\n",
       "       HpHp_L0.1_covariance  HpHp_L0.1_pcc  HpHp_L0.01_weight  \\\n",
       "30069         -4.300000e-10  -1.050000e-06          18.488216   \n",
       "3563          -7.938604e+00  -1.563288e-01          18.294705   \n",
       "9406          -1.850000e-12  -7.200000e-08          19.149283   \n",
       "46005          0.000000e+00   0.000000e+00           1.677611   \n",
       "36074         -5.680000e-11  -9.940000e-07          19.118733   \n",
       "\n",
       "       HpHp_L0.01_mean  HpHp_L0.01_std  HpHp_L0.01_magnitude  \\\n",
       "30069        66.057505        0.828709            116.262918   \n",
       "3563         70.153435        6.971186             99.914476   \n",
       "9406         66.079987        0.976445            115.448327   \n",
       "46005        74.000000        0.000000             95.268043   \n",
       "36074        66.034240        0.640086            115.691611   \n",
       "\n",
       "       HpHp_L0.01_radius  HpHp_L0.01_covariance  HpHp_L0.01_pcc  \n",
       "30069         217.397737              -0.245503       -0.020092  \n",
       "3563           73.747515              -1.438903       -0.027714  \n",
       "9406          238.893604              -0.361232       -0.023935  \n",
       "46005           0.000000               0.000000        0.000000  \n",
       "36074         232.107760              -0.246350       -0.025262  \n",
       "\n",
       "[5 rows x 115 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop labels from training dataset\n",
    "data=data.drop(columns='type')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0572ff5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L5_mean</th>\n",
       "      <th>MI_dir_L5_variance</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L3_mean</th>\n",
       "      <th>MI_dir_L3_variance</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L1_mean</th>\n",
       "      <th>MI_dir_L1_variance</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HpHp_L0.1_radius</th>\n",
       "      <th>HpHp_L0.1_covariance</th>\n",
       "      <th>HpHp_L0.1_pcc</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "      <th>HpHp_L0.01_mean</th>\n",
       "      <th>HpHp_L0.01_std</th>\n",
       "      <th>HpHp_L0.01_magnitude</th>\n",
       "      <th>HpHp_L0.01_radius</th>\n",
       "      <th>HpHp_L0.01_covariance</th>\n",
       "      <th>HpHp_L0.01_pcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30069</th>\n",
       "      <td>-0.582847</td>\n",
       "      <td>-0.171045</td>\n",
       "      <td>-0.095451</td>\n",
       "      <td>-0.581106</td>\n",
       "      <td>-0.173175</td>\n",
       "      <td>-0.097830</td>\n",
       "      <td>-0.576022</td>\n",
       "      <td>-0.176472</td>\n",
       "      <td>-0.107931</td>\n",
       "      <td>-0.567296</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147203</td>\n",
       "      <td>-0.035332</td>\n",
       "      <td>-0.018887</td>\n",
       "      <td>0.107372</td>\n",
       "      <td>-0.160534</td>\n",
       "      <td>-0.293008</td>\n",
       "      <td>-0.080878</td>\n",
       "      <td>-0.196836</td>\n",
       "      <td>-0.044407</td>\n",
       "      <td>-0.020092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3563</th>\n",
       "      <td>-0.582836</td>\n",
       "      <td>-0.171045</td>\n",
       "      <td>-0.095451</td>\n",
       "      <td>-0.581065</td>\n",
       "      <td>-0.173173</td>\n",
       "      <td>-0.097830</td>\n",
       "      <td>-0.575964</td>\n",
       "      <td>-0.174943</td>\n",
       "      <td>-0.107934</td>\n",
       "      <td>-0.567489</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147361</td>\n",
       "      <td>-0.037030</td>\n",
       "      <td>-1.127881</td>\n",
       "      <td>0.100243</td>\n",
       "      <td>-0.113353</td>\n",
       "      <td>-0.149582</td>\n",
       "      <td>-0.211880</td>\n",
       "      <td>-0.199550</td>\n",
       "      <td>-0.044627</td>\n",
       "      <td>-0.027714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9406</th>\n",
       "      <td>-0.582866</td>\n",
       "      <td>-0.171045</td>\n",
       "      <td>-0.095451</td>\n",
       "      <td>-0.581174</td>\n",
       "      <td>-0.173172</td>\n",
       "      <td>-0.097830</td>\n",
       "      <td>-0.576044</td>\n",
       "      <td>-0.166932</td>\n",
       "      <td>-0.105848</td>\n",
       "      <td>-0.567498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145898</td>\n",
       "      <td>-0.035332</td>\n",
       "      <td>-0.018880</td>\n",
       "      <td>0.131726</td>\n",
       "      <td>-0.160275</td>\n",
       "      <td>-0.289558</td>\n",
       "      <td>-0.087406</td>\n",
       "      <td>-0.196430</td>\n",
       "      <td>-0.044428</td>\n",
       "      <td>-0.023935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46005</th>\n",
       "      <td>1.871299</td>\n",
       "      <td>-0.092685</td>\n",
       "      <td>-0.095445</td>\n",
       "      <td>1.833394</td>\n",
       "      <td>-0.091725</td>\n",
       "      <td>-0.097817</td>\n",
       "      <td>1.801526</td>\n",
       "      <td>-0.087483</td>\n",
       "      <td>-0.107958</td>\n",
       "      <td>1.844882</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148871</td>\n",
       "      <td>-0.035332</td>\n",
       "      <td>-0.018880</td>\n",
       "      <td>-0.511940</td>\n",
       "      <td>-0.069044</td>\n",
       "      <td>-0.312358</td>\n",
       "      <td>-0.249112</td>\n",
       "      <td>-0.200944</td>\n",
       "      <td>-0.044362</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36074</th>\n",
       "      <td>-0.582425</td>\n",
       "      <td>-0.171045</td>\n",
       "      <td>-0.095451</td>\n",
       "      <td>-0.580286</td>\n",
       "      <td>-0.173173</td>\n",
       "      <td>-0.097830</td>\n",
       "      <td>-0.575694</td>\n",
       "      <td>-0.175215</td>\n",
       "      <td>-0.107983</td>\n",
       "      <td>-0.567800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144268</td>\n",
       "      <td>-0.035332</td>\n",
       "      <td>-0.018887</td>\n",
       "      <td>0.130601</td>\n",
       "      <td>-0.160802</td>\n",
       "      <td>-0.297412</td>\n",
       "      <td>-0.085456</td>\n",
       "      <td>-0.196558</td>\n",
       "      <td>-0.044407</td>\n",
       "      <td>-0.025262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  MI_dir_L3_weight  \\\n",
       "30069         -0.582847       -0.171045           -0.095451         -0.581106   \n",
       "3563          -0.582836       -0.171045           -0.095451         -0.581065   \n",
       "9406          -0.582866       -0.171045           -0.095451         -0.581174   \n",
       "46005          1.871299       -0.092685           -0.095445          1.833394   \n",
       "36074         -0.582425       -0.171045           -0.095451         -0.580286   \n",
       "\n",
       "       MI_dir_L3_mean  MI_dir_L3_variance  MI_dir_L1_weight  MI_dir_L1_mean  \\\n",
       "30069       -0.173175           -0.097830         -0.576022       -0.176472   \n",
       "3563        -0.173173           -0.097830         -0.575964       -0.174943   \n",
       "9406        -0.173172           -0.097830         -0.576044       -0.166932   \n",
       "46005       -0.091725           -0.097817          1.801526       -0.087483   \n",
       "36074       -0.173173           -0.097830         -0.575694       -0.175215   \n",
       "\n",
       "       MI_dir_L1_variance  MI_dir_L0.1_weight  ...  HpHp_L0.1_radius  \\\n",
       "30069           -0.107931           -0.567296  ...         -0.147203   \n",
       "3563            -0.107934           -0.567489  ...         -0.147361   \n",
       "9406            -0.105848           -0.567498  ...         -0.145898   \n",
       "46005           -0.107958            1.844882  ...         -0.148871   \n",
       "36074           -0.107983           -0.567800  ...         -0.144268   \n",
       "\n",
       "       HpHp_L0.1_covariance  HpHp_L0.1_pcc  HpHp_L0.01_weight  \\\n",
       "30069             -0.035332      -0.018887           0.107372   \n",
       "3563              -0.037030      -1.127881           0.100243   \n",
       "9406              -0.035332      -0.018880           0.131726   \n",
       "46005             -0.035332      -0.018880          -0.511940   \n",
       "36074             -0.035332      -0.018887           0.130601   \n",
       "\n",
       "       HpHp_L0.01_mean  HpHp_L0.01_std  HpHp_L0.01_magnitude  \\\n",
       "30069        -0.160534       -0.293008             -0.080878   \n",
       "3563         -0.113353       -0.149582             -0.211880   \n",
       "9406         -0.160275       -0.289558             -0.087406   \n",
       "46005        -0.069044       -0.312358             -0.249112   \n",
       "36074        -0.160802       -0.297412             -0.085456   \n",
       "\n",
       "       HpHp_L0.01_radius  HpHp_L0.01_covariance  HpHp_L0.01_pcc  \n",
       "30069          -0.196836              -0.044407       -0.020092  \n",
       "3563           -0.199550              -0.044627       -0.027714  \n",
       "9406           -0.196430              -0.044428       -0.023935  \n",
       "46005          -0.200944              -0.044362        0.000000  \n",
       "36074          -0.196558              -0.044407       -0.025262  \n",
       "\n",
       "[5 rows x 115 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standardize numerical columns\n",
    "def standardize(df,col):\n",
    "    df[col]= (df[col]-df[col].mean())/df[col].std()\n",
    "\n",
    "data_st=data.copy()\n",
    "for i in (data_st.iloc[:,:-1].columns):\n",
    "    standardize (data_st,i)\n",
    "\n",
    "data_st.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee4f6ae",
   "metadata": {},
   "source": [
    "# Different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90becacd",
   "metadata": {},
   "source": [
    "## DBSCAN - Density-Based Spatial Clustering of Applications with Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a273123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute DBSCAN\n",
    "db = DBSCAN(eps=4, min_samples=13000).fit(data_st) # variar eps e min_samples para encontrar n clusters desejado (use 13000)\n",
    "db.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28886ef7",
   "metadata": {},
   "source": [
    "for x in range(10, 0, -1):\n",
    "    eps = 1/(11-x)\n",
    "    samples = 130*x\n",
    "    db = DBSCAN(eps=eps, min_samples=samples).fit(data_st)\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "    \n",
    "    print('EPS: ', eps, 'Min samples: ', samples)\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "\n",
    "    print('Estimated number of clusters: %d' % n_clusters_)\n",
    "    print('Estimated number of noise points: %d' % n_noise_)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b4b6391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign length:  43810   Gafgyt length:  14538\n",
      "\n",
      "Results: \n",
      "Grouped as:  Benign:  40258   Malicious:  14391   Outlier:  3699\n",
      "Correct:  54638   Uncorrect:  11   Outliers:  3699\n",
      "Accuracy: (%) Benign data:  0.9189226204062999 Malicious data:  0.9898885678910442\n",
      "Complete data:  0.9364159868375951\n"
     ]
    }
   ],
   "source": [
    "classe1 = 0\n",
    "classe2 = 0\n",
    "outlier = 0\n",
    "correct = 0\n",
    "uncorrect = 0\n",
    "outlier2 = 0\n",
    "for i in range(len(data_st)):\n",
    "    if(db.labels_[i] == 0):\n",
    "        classe1+=1\n",
    "    elif(db.labels_[i] == 1):\n",
    "        classe2+=1\n",
    "    elif(db.labels_[i] == -1):\n",
    "        outlier+=1\n",
    "    \n",
    "    if((db.labels_[i] == 0 and labels_full.type_benign[data_st.index[i]] == 1) or\n",
    "       (db.labels_[i] == 1 and labels_full.type_gafgyt_combo[data_st.index[i]] == 1)):\n",
    "        correct+=1\n",
    "    elif((db.labels_[i] == 0 and labels_full.type_benign[data_st.index[i]] == 0) or\n",
    "       (db.labels_[i] == 1 and labels_full.type_gafgyt_combo[data_st.index[i]] == 0)):\n",
    "        uncorrect+=1\n",
    "    else:\n",
    "        outlier2+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    #dbscan_label = db.labels_[i]\n",
    "print('Benign length: ', len(benign), ' ', 'Gafgyt length: ', len(g_combo))\n",
    "print('\\nResults: ')\n",
    "print('Grouped as: ', 'Benign: ', classe1, ' ', 'Malicious: ', classe2, ' ', 'Outlier: ', outlier)\n",
    "print('Correct: ', correct,' ', 'Uncorrect: ', uncorrect,' ', 'Outliers: ', outlier2)\n",
    "\n",
    "print('Accuracy: (%)', 'Benign data: ', classe1/len(benign), 'Malicious data: ', classe2/len(g_combo))\n",
    "print('Complete data: ', correct/len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da8829c",
   "metadata": {},
   "source": [
    "## Isolation Forests (IF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dafce879",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = IsolationForest(n_estimators=100, max_samples='auto', contamination='auto',\n",
    "                      max_features=1.0, bootstrap=False, n_jobs=None, random_state=0,\n",
    "                      verbose=0, warm_start=False).fit(data_st)\n",
    "result = clf.predict(data_st) # -1 => outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "622b09c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign length:  43810   Gafgyt length:  14538\n",
      "\n",
      "Results: \n",
      "Grouped as:  Benign:  56573   Malicious:  1775\n",
      "Confusion matrix:  \tTP: 42053 FP: 1757 \n",
      " \t\t\t FN: 14520 TN: 18\n",
      "Accuracy (%):  0.7210358538424625 \n",
      "Precision:  0.9598950011412919 \n",
      "Recall:  0.7433404627649232 \n",
      "F-score:  0.837851030552982\n",
      "\n",
      "Legend: \n",
      "TP: True Positive (Benign data classified as benign) \n",
      "FP: False Positive (Benign data classified as malicious)\n",
      "\n",
      "FN: False Negative (Malicious data classified as benign) \n",
      "TN: True Negative (Malicious data classified as malicious)\n"
     ]
    }
   ],
   "source": [
    "normal = 0\n",
    "malicious = 0\n",
    "TP = 0; FP = 0; TN = 0; FN = 0\n",
    "\n",
    "for i in range(len(data_st)):\n",
    "    if(result[i] == 1):\n",
    "        normal+=1\n",
    "    elif(result[i] == -1):\n",
    "        malicious+=1\n",
    "\n",
    "    \n",
    "    if(result[i] == 1 and labels_full.type_benign[data_st.index[i]] == 1):\n",
    "        TP+=1\n",
    "    elif(result[i] == 1 and labels_full.type_benign[data_st.index[i]] == 0):\n",
    "        FN+=1\n",
    "    elif(result[i] == -1 and labels_full.type_benign[data_st.index[i]] == 1):\n",
    "        FP+=1\n",
    "    elif(result[i] == -1 and labels_full.type_benign[data_st.index[i]] == 0):\n",
    "        TN+=1\n",
    "        \n",
    "\n",
    "accuracy = (TP + TN)/(TP + TN + FP + FN)        \n",
    "precision = TP/(TP + FP)\n",
    "recall = TP/(TP+FN)\n",
    "fscore = 2*precision*recall/(precision+recall)\n",
    "\n",
    "\n",
    "print('Benign length: ', len(benign), ' ', 'Gafgyt length: ', len(g_combo))\n",
    "print('\\nResults: ')\n",
    "print('Grouped as: ', 'Benign: ', normal, ' ', 'Malicious: ', malicious)\n",
    "\n",
    "print('\\nConfusion matrix: ', '\\tTP:', TP, 'FP:', FP, '\\n', '\\t\\t\\t', 'FN:', FN, 'TN:', TN)\n",
    "print('Accuracy (%): ', accuracy, '\\nPrecision: ', precision, '\\nRecall: ', recall, '\\nF-score: ', fscore)\n",
    "\n",
    "\n",
    "print('\\nLegend:','\\nTP: True Positive (Benign data classified as benign)', '\\nFP: False Positive (Benign data classified as malicious)')\n",
    "print('\\nFN: False Negative (Malicious data classified as benign)', '\\nTN: True Negative (Malicious data classified as malicious)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1499cd",
   "metadata": {},
   "source": [
    "## Local Outlier Factor (LOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9adc4e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1, ...,  1,  1,  1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LocalOutlierFactor(n_neighbors=20, algorithm='auto', leaf_size=30, \n",
    "                         metric='minkowski', p=2, metric_params=None, \n",
    "                         contamination='auto', novelty=False, n_jobs=None)\n",
    "result = clf.fit_predict(data_st)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfcdb94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign length:  43810   Gafgyt length:  14538\n",
      "\n",
      "Results: \n",
      "Grouped as:  Benign:  54196   Malicious:  4152\n",
      "Confusion matrix:  \tTP: 39842 FP: 3968 \n",
      " \t\t\t FN: 14354 TN: 184\n",
      "Accuracy (%):  0.6859875231370398 \n",
      "Precision:  0.9094270714448756 \n",
      "Recall:  0.7351465052771422 \n",
      "F-score:  0.8130522621064017\n",
      "\n",
      "Legend: \n",
      "TP: True Positive (Benign data classified as benign) \n",
      "FP: False Positive (Benign data classified as malicious)\n",
      "\n",
      "FN: False Negative (Malicious data classified as benign) \n",
      "TN: True Negative (Malicious data classified as malicious)\n"
     ]
    }
   ],
   "source": [
    "normal = 0\n",
    "malicious = 0\n",
    "TP = 0; FP = 0; TN = 0; FN = 0\n",
    "\n",
    "for i in range(len(data_st)):\n",
    "    if(result[i] == 1):\n",
    "        normal+=1\n",
    "    elif(result[i] == -1):\n",
    "        malicious+=1\n",
    "\n",
    "    \n",
    "    if(result[i] == 1 and labels_full.type_benign[data_st.index[i]] == 1):\n",
    "        TP+=1\n",
    "    elif(result[i] == 1 and labels_full.type_benign[data_st.index[i]] == 0):\n",
    "        FN+=1\n",
    "    elif(result[i] == -1 and labels_full.type_benign[data_st.index[i]] == 1):\n",
    "        FP+=1\n",
    "    elif(result[i] == -1 and labels_full.type_benign[data_st.index[i]] == 0):\n",
    "        TN+=1\n",
    "        \n",
    "\n",
    "accuracy = (TP + TN)/(TP + TN + FP + FN)        \n",
    "precision = TP/(TP + FP)\n",
    "recall = TP/(TP+FN)\n",
    "fscore = 2*precision*recall/(precision+recall)\n",
    "\n",
    "\n",
    "print('Benign length: ', len(benign), ' ', 'Gafgyt length: ', len(g_combo))\n",
    "print('\\nResults: ')\n",
    "print('Grouped as: ', 'Benign: ', normal, ' ', 'Malicious: ', malicious)\n",
    "\n",
    "print('\\nConfusion matrix: ', '\\tTP:', TP, 'FP:', FP, '\\n', '\\t\\t\\t', 'FN:', FN, 'TN:', TN)\n",
    "print('Accuracy (%): ', accuracy, '\\nPrecision: ', precision, '\\nRecall: ', recall, '\\nF-score: ', fscore)\n",
    "\n",
    "\n",
    "print('\\nLegend:','\\nTP: True Positive (Benign data classified as benign)', '\\nFP: False Positive (Benign data classified as malicious)')\n",
    "print('\\nFN: False Negative (Malicious data classified as benign)', '\\nTN: True Negative (Malicious data classified as malicious)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6830ae9a",
   "metadata": {},
   "source": [
    "## Elliptic Envelope (EE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d3b32eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:647: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\"The covariance matrix associated to your dataset \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2589.706287339770824 > -2592.140862478894178). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2607.925281390894270 > -2612.026542038363914). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2522.991652177051037 > -2537.043721552507577). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2620.429574265137489 > -2620.994690978101062). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2645.488808305173279 > -2650.108836558481926). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2542.901705869991019 > -2551.858591689790046). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2628.388302900524195 > -2628.803836087214222). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2611.267176965835461 > -2621.763470884634444). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2534.113802051107541 > -2535.556606660205944). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2638.435039318232612 > -2639.327401325929259). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2587.347992930101100 > -2593.557869449687587). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2477.870945898746413 > -2482.586022200976913). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2576.578279460135036 > -2586.080358328878901). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2602.682120136942103 > -2611.085223183820290). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2570.954129242641557 > -2581.858585881550425). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2619.909122158991067 > -2621.806417586574298). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2582.559659850838216 > -2584.413172605586169). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2557.148602088966982 > -2559.315984279657641). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2457.773913602009998 > -2458.745581566447072). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2515.357775819496510 > -2524.590367584888554). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2480.573897932432828 > -2482.577173261679036). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2613.596608892560198 > -2613.958882861283200). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2440.441793207758110 > -2440.660738512107400). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2472.228984893595225 > -2473.387785255873041). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2506.590433171591485 > -2508.428989910934888). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2593.389724389317962 > -2593.977949904126490). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2666.317942027305889 > -2667.693895456562586). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2480.831972413488529 > -2481.001633232771837). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\Users\\gustavo\\anaconda3\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-2537.871604240800025 > -2547.088898334675832). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n"
     ]
    }
   ],
   "source": [
    "cov = EllipticEnvelope(store_precision=True, assume_centered=False, support_fraction=None,\n",
    "                       contamination=0.1, random_state=None).fit(data_st) \n",
    "# maybe it is better to use Benign to fit the data and then use data_st to predict\n",
    "# predict returns 1 for an inlier and -1 for an outlier\n",
    "result = cov.predict(data_st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "891d2d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign length:  43810   Gafgyt length:  14538\n",
      "\n",
      "Results: \n",
      "Grouped as:  Benign:  52512   Malicious:  5836\n",
      "Confusion matrix:  \tTP: 37996 FP: 5814 \n",
      " \t\t\t FN: 14516 TN: 22\n",
      "Accuracy (%):  0.651573318708439 \n",
      "Precision:  0.8672905729285552 \n",
      "Recall:  0.7235679463741621 \n",
      "F-score:  0.7889371067876498\n",
      "\n",
      "Legend: \n",
      "TP: True Positive (Benign data classified as benign) \n",
      "FP: False Positive (Benign data classified as malicious)\n",
      "\n",
      "FN: False Negative (Malicious data classified as benign) \n",
      "TN: True Negative (Malicious data classified as malicious)\n"
     ]
    }
   ],
   "source": [
    "normal = 0\n",
    "malicious = 0\n",
    "TP = 0; FP = 0; TN = 0; FN = 0\n",
    "\n",
    "for i in range(len(data_st)):\n",
    "    if(result[i] == 1):\n",
    "        normal+=1\n",
    "    elif(result[i] == -1):\n",
    "        malicious+=1\n",
    "\n",
    "    \n",
    "    if(result[i] == 1 and labels_full.type_benign[data_st.index[i]] == 1):\n",
    "        TP+=1\n",
    "    elif(result[i] == 1 and labels_full.type_benign[data_st.index[i]] == 0):\n",
    "        FN+=1\n",
    "    elif(result[i] == -1 and labels_full.type_benign[data_st.index[i]] == 1):\n",
    "        FP+=1\n",
    "    elif(result[i] == -1 and labels_full.type_benign[data_st.index[i]] == 0):\n",
    "        TN+=1\n",
    "        \n",
    "\n",
    "accuracy = (TP + TN)/(TP + TN + FP + FN)        \n",
    "precision = TP/(TP + FP)\n",
    "recall = TP/(TP+FN)\n",
    "fscore = 2*precision*recall/(precision+recall)\n",
    "\n",
    "\n",
    "print('Benign length: ', len(benign), ' ', 'Gafgyt length: ', len(g_combo))\n",
    "print('\\nResults: ')\n",
    "print('Grouped as: ', 'Benign: ', normal, ' ', 'Malicious: ', malicious)\n",
    "\n",
    "print('\\nConfusion matrix: ', '\\tTP:', TP, 'FP:', FP, '\\n', '\\t\\t\\t', 'FN:', FN, 'TN:', TN)\n",
    "print('Accuracy (%): ', accuracy, '\\nPrecision: ', precision, '\\nRecall: ', recall, '\\nF-score: ', fscore)\n",
    "\n",
    "\n",
    "print('\\nLegend:','\\nTP: True Positive (Benign data classified as benign)', '\\nFP: False Positive (Benign data classified as malicious)')\n",
    "print('\\nFN: False Negative (Malicious data classified as benign)', '\\nTN: True Negative (Malicious data classified as malicious)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9b9a96",
   "metadata": {},
   "source": [
    "## One-Class Support Vector Machine (1CSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "384eebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneClassSVM(kernel='rbf', degree=3, gamma='auto',\n",
    "                  coef0=0.0, tol=0.001, nu=0.35, shrinking=True,\n",
    "                  cache_size=200, verbose=False, max_iter=- 1).fit(data_st)\n",
    "result = clf.predict(data_st)\n",
    "\n",
    "#clf.score_samples(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abe9ed95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign length:  43810   Gafgyt length:  14538\n",
      "\n",
      "Results: \n",
      "Grouped as:  Benign:  37929   Malicious:  20419\n",
      "Confusion matrix:  \tTP: 31421 FP: 12389 \n",
      " \t\t\t FN: 6508 TN: 8030\n",
      "Accuracy (%):  0.6761328580242681 \n",
      "Precision:  0.7172106824925816 \n",
      "Recall:  0.8284162514171215 \n",
      "F-score:  0.7688129289568015\n",
      "\n",
      "Legend: \n",
      "TP: True Positive (Benign data classified as benign) \n",
      "FP: False Positive (Benign data classified as malicious)\n",
      "\n",
      "FN: False Negative (Malicious data classified as benign) \n",
      "TN: True Negative (Malicious data classified as malicious)\n"
     ]
    }
   ],
   "source": [
    "normal = 0\n",
    "malicious = 0\n",
    "TP = 0; FP = 0; TN = 0; FN = 0\n",
    "\n",
    "for i in range(len(data_st)):\n",
    "    if(result[i] == 1):\n",
    "        normal+=1\n",
    "    elif(result[i] == -1):\n",
    "        malicious+=1\n",
    "\n",
    "    \n",
    "    if(result[i] == 1 and labels_full.type_benign[data_st.index[i]] == 1):\n",
    "        TP+=1\n",
    "    elif(result[i] == 1 and labels_full.type_benign[data_st.index[i]] == 0):\n",
    "        FN+=1\n",
    "    elif(result[i] == -1 and labels_full.type_benign[data_st.index[i]] == 1):\n",
    "        FP+=1\n",
    "    elif(result[i] == -1 and labels_full.type_benign[data_st.index[i]] == 0):\n",
    "        TN+=1\n",
    "        \n",
    "\n",
    "accuracy = (TP + TN)/(TP + TN + FP + FN)        \n",
    "precision = TP/(TP + FP)\n",
    "recall = TP/(TP+FN)\n",
    "fscore = 2*precision*recall/(precision+recall)\n",
    "\n",
    "\n",
    "print('Benign length: ', len(benign), ' ', 'Gafgyt length: ', len(g_combo))\n",
    "print('\\nResults: ')\n",
    "print('Grouped as: ', 'Benign: ', normal, ' ', 'Malicious: ', malicious)\n",
    "\n",
    "print('\\nConfusion matrix: ', '\\tTP:', TP, 'FP:', FP, '\\n', '\\t\\t\\t', 'FN:', FN, 'TN:', TN)\n",
    "print('Accuracy (%): ', accuracy, '\\nPrecision: ', precision, '\\nRecall: ', recall, '\\nF-score: ', fscore)\n",
    "\n",
    "print('\\nLegend:','\\nTP: True Positive (Benign data classified as benign)', '\\nFP: False Positive (Benign data classified as malicious)')\n",
    "print('\\nFN: False Negative (Malicious data classified as benign)', '\\nTN: True Negative (Malicious data classified as malicious)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8850f5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d1a5324",
   "metadata": {},
   "source": [
    "## All 5 algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40d567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3468b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \"classifiers\" to be used\n",
    "algorithms = {\n",
    "    \"DBSCAN - Density-Based Spatial Clustering of Applications with Noise\": DBSCAN(eps=4, min_samples=1300),\n",
    "    \"Isolation Forest\": IsolationForest(random_state=0), \n",
    "    \"Local Outlier Factor\": LocalOutlierFactor(n_neighbors=20, contamination=0.1),\n",
    "    \"EllipticEnvelope\": EllipticEnvelope(support_fraction=1., contamination=0.25),\n",
    "    \"OCSVM\": OneClassSVM(nu=0.25, gamma=0.35)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae21e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (alg_name, alg) in enumerate(algorithms.items()):\n",
    "    alg.fit(data_st)\n",
    "    ## show some results and evaluate them\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
